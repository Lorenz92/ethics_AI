# MME

* Asimov’s laws of robotics
* gauge social expectations about how autonomous vehicles should solve moral dilemmas.
* First challeng: high dimensionality of the problem
* Second challenge: data must be collected worldwide, in order to assess demographic and cultural moderators of ethical preferences
* 39.61M decisions from 233 countries
* Questions:
  * First, what are the relative importances of the nine preferences we explored on the platform, when data are aggregated worldwide?
  * Second, does the intensity of each preference depend on the individual characteristics of respondents?
  * Third, can we identify clusters of coun* tries with homogeneous vectors of moral preferences?
  * And fourth, do cultural and economic variations between countries predict variations in their vectors of moral preferences?
* AMCE scores
* German Ethical Rule number 7 (German Ethics Commission on Automated and Connected Driving) unambiguously states that in dilemma situations, the protection of human life should enjoy top priority over the protection of other animal life. This rule is in clear agreement with social expectations assessed through the Moral Machine
* On the other hand, German Ethical Rule number 9 does not take a clear stance on whether and when autonomous vehicles should be programmed to sacrifice the few to spare the many, but leaves this possibility open: it is important, thus, to know that there would be strong public agreement with such programming, even if it is not mandated through regulation
  * By contrast, German Ethical Rule number 9 also states that any distinction based on personal features, such as age, should be prohibited
  * This clearly clashes with the strong preference for sparing the young (such as children) that is assessed through the Moral Machine

## Individual variations

* We assessed individual variations by further analysing the responses of the subgroup of Moral Machine users (n = 492,921) who completed the optional demographic survey on age, education, gender, income, and political and religious views, to assess whether preferences were modulated by these six characteristics. First, when we include all six characteristic variables in regression*based estimators of each of the nine attributes, we find that individual variations have no sizable impact on any of the nine attributes (all below 0.1)

## Cultural clusters

* We selected the 130 countries with at least 100 respondents (n range 101–448,125), standardized the nine target AMCEs of each country, and conducted a hierarchical clustering on these nine scores, using Euclidean distance and Ward’s minimum variance method20. This analysis identified three distinct ‘moral clusters’ of countries
  * Western cluster: NA, EU countries (Protestant, Catholic, and Orthodox Christian cultural groups)
  * Eastern cluster: contains many far eastern countries such as Japan and Taiwan that belong to the Confucianist cultural group, and Islamic countries such as Indonesia, Pakistan and Saudi Arabia.
  * The third cluster (a broadly Southern cluster) consists of the Latin American countries of Central and South America, in addition to some countries that are characterized in part by French influence (for example, metropolitan France, French overseas territories, and territories that were at some point under French leadership).
* This clustering pattern (which is fairly robust; Extended Data Fig. 5) suggests that geographical and cultural proximity may allow groups of territories to converge on shared preferences for machine ethics
* Between*cluster differences, though, may pose greater problems. Clusters largely differ in the weight they give to some preferences.

### Notes

* PERSONE FREGA UN CAZZO: si documentano solo quando succede qualcosa, schianto

## Country-level predictors

* The more culturally similar a country is to the United States, the more similarly its people play the Moral Machine (the similar the countries the similar the responses to MM)
* Should those who are crossing the street illegally benefit from the same protection as pedestrians who cross legally?
  * Participants from countries that are poorer and suffer from weaker institutions are more tolerant of pedestrians who cross illegally, presumably because of their experience of lower rule compliance and weaker punishment of rule deviation. This observation limits the generalizability of the recent German ethics guideline, for example, which state that “parties involved in the generation of mobility risks must not sacrifice non*involved parties.”

### Notes

* SIMILARITA' CULTURALE: SCHIACCIO IL RICCO O IL POVERO? ITALIANO O CINESE? DIPENDE SE SONO RICCO, POVERO, ITALIANO O CINESE

* THE GOOD PLACE: SISTEMA PUNTI, SCHIACCIO GENTE IN MACCHINA IN BASE AI PUNTI -> PROBLEMA: CHI SCEGLIE I PUNTI DA DARE A OGNI AZIONE?

## Discussion

* Our data helped us to identify three strong preferences that can serve as building blocks for discussions of universal machine ethics, even if they are not ultimately endorsed by policymakers: the preference for sparing human lives, the preference for sparing more lives, and the preference for sparing young lives. Some preferences based on gender or social status vary considerably across countries, and appear to reflect underlying societallevel preferences for egalitarianism
* But the fact that our samples are not guaranteed to be representative means that policymakers should not embrace our data as the final word on societal preferences—even if our sample is arguably close to the internet-connected, tech-savvy population that is interested in driverless car technology, and more likely to participate in early adoption.
* Even with a sample size as large as ours, we could not do justice to all of the complexity of autonomous vehicle dilemmas. For example, we did not introduce uncertainty about the fates of the characters, and we did not introduce any uncertainty about the classification of these characters. In our scenarios, characters were recognized as adults, children, and so on with 100% certainty, and life-and-death outcomes were predicted with 100% certainty. These assumptions are technologically unrealistic, but they were necessary to keep the project tractable.
* Indeed, we can embrace the challenges of machine ethics as a unique opportunity to decide, as a community, what we believe to be right or wrong; and to make sure that machines, unlike humans, unerringly follow these moral preferences
